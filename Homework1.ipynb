{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e920c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###q1\n",
    "# feel free to just use the following if you prefer...\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aed191b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame has 391 rows and 11 columns.\n"
     ]
    }
   ],
   "source": [
    "###q2\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "rows, columns = df.shape\n",
    "\n",
    "# Print the number of rows and columns\n",
    "print(f\"The DataFrame has {rows} rows and {columns} columns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d680d2d4",
   "metadata": {},
   "source": [
    "observations ：In the context, an observation refers to each individual data from the dataset. \n",
    "variable ：the characteristic of the observation measured or recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40358899",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/66e34493-e778-8001-9794-03c78f5cd845"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ad5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###q3\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "\n",
    "# Get summary statistics for numeric columns\n",
    "numeric_summary = df.describe()\n",
    "\n",
    "# Get a general summary of the DataFrame (including non-numeric columns)\n",
    "general_summary = df.info()\n",
    "\n",
    "# Print the numeric summary\n",
    "print(numeric_summary)\n",
    "\n",
    "# Print the general summary\n",
    "print(general_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa5125",
   "metadata": {},
   "source": [
    "we can use info(), describe(), value_counts()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b288b5d",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/66e346d4-578c-8001-b3a3-6f95c09b88b8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b11a0",
   "metadata": {},
   "source": [
    "Q4: Discrepancy in the Number of Columns Analyzed\n",
    "df.shape: This function returns the total number of rows and columns in the dataset, including both numeric and non-numeric variables.\n",
    "df.describe(): By default, df.describe() only analyzes numeric columns\n",
    "Discrepancy in the Values Reported in the \"Count\" Column\n",
    "df.shape: This simply counts the number of rows in the dataset, regardless of missing values.\n",
    "df.describe(): The \"count\" column in df.describe() reports the number of non-missing (non-null) values for each numeric column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df58f5f",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/66e34803-cfc4-8001-9e06-1b4291c4289b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde81456",
   "metadata": {},
   "source": [
    "Q5:\n",
    "The difference between attribude and method:\n",
    "Attribute is a property of a pandas object which dont need to assess with a function, no needing parentheses\n",
    "Method is a function that can be applied to a pandas object, needing parentheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3177a9c2",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/66e34852-e330-8001-acb0-9953bff385be"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e2a5a",
   "metadata": {},
   "source": [
    "Q6:\n",
    "count: It indicates how many valid data points there are for a particular variable.\n",
    "mean: It indicates the average number of the data.\n",
    "standard Deviation: A measure of the spread or dispersion of the values in the column.\n",
    "minimum: The smallest value in the column.\n",
    "25th Percentile (25%): The value below which 25% of the data points fall.\n",
    "50th Percentile (50%): The value below which 50% of the data points fall.\n",
    "75th Percentile (75%): The value below which 75% of the data points fall.\n",
    "Maximum:  The largest value in the column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe90e105",
   "metadata": {},
   "source": [
    "Q7:\n",
    "  You have a dataset of customer information where each row represents a customer and each column represents important details such as name, age, email, and purchase amount. Some rows have missing values in the \"email\" and \"age\" columns, but most of the data is complete in other columns. Instead of deleting an entire column of customer emails (which would remove valuable information), you prefer to drop rows that have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ccc314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame with some missing values\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, None, 30, 28],\n",
    "    'Email': ['alice@example.com', None, 'charlie@example.com', 'david@example.com'],\n",
    "    'PurchaseAmount': [500, 600, None, 700]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop rows with any missing values\n",
    "cleaned_df = df.dropna()\n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "print(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82afdd",
   "metadata": {},
   "source": [
    "df.dropna( ) can be used when you want to remove rows with missing values and keep enough data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a437bbba",
   "metadata": {},
   "source": [
    "You are working with a dataset that contains information about a company's employees, including name, age, department, salary, and an optional \"LinkedIn\" profile column. However, many employees do not have LinkedIn profiles, and the column is largely incomplete (with more than 80% missing values). Since the LinkedIn profile is not essential to your analysis, and removing rows with missing LinkedIn profiles would unnecessarily reduce the amount of available data in other columns, you decide to delete the entire LinkedIn column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f23b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame with many missing values in the 'LinkedIn' column\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 35, 30, 28],\n",
    "    'Department': ['HR', 'Finance', 'IT', 'Marketing'],\n",
    "    'Salary': [50000, 60000, 55000, 58000],\n",
    "    'LinkedIn': [None, 'linkedin.com/bob', None, None]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Delete the 'LinkedIn' column\n",
    "del df['LinkedIn']\n",
    "\n",
    "# Print the DataFrame after deleting the column\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e383490",
   "metadata": {},
   "source": [
    "It is appropriate for the situation which contains some inportant information and you want to preserve. It is opposite to the df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0d89ca",
   "metadata": {},
   "source": [
    "Reason 1: preserve useful data\n",
    "Because if you use df.dropna() first, you risk removing rows that have missing values in columns you plan to delete anyway. It may delete many useful data causing the lack of data.\n",
    "Reason 2 3 4: streamlines Data Cleaning，Reduces Memory Usage and Processing Time， Clear Data Cleaning Workflow\n",
    "They can share a common explaination. Deleting irrelevant or low-quality columns first, the complexity will reduce first. Then, it is easy for df.dropna() to clean. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9700e5",
   "metadata": {},
   "source": [
    "Remove irrelevant column: The LinkedIn column has many missing values, and we consider it irrelevant to the main analysis. We'll use del df[ ] to remove it completely.\n",
    "Drop rows with missing values in important columns: We want to keep the rows where both the Age and Salary columns have non-missing values, so we'll use df.dropna() to remove rows with missing values in these essential columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92544ee",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/66e348da-0010-8001-bd49-7bf6e843ff20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dd4414",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a854bce1",
   "metadata": {},
   "source": [
    "Question8\n",
    "1: df.groupby(\"col1\") group data according to values in the column1. After first step, you need to operate grouping in the column2. Then, you can use several definition like mean, count to summary the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac341010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "group_sex_stats = df.groupby(\"pclass\")[\"sex\"].describe()\n",
    "print (group_sex_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c1003",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It should show men and women in different classes. And then summary the top, fre and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0261e29",
   "metadata": {},
   "source": [
    "Question8\n",
    "2: df.describe() summarises for all columns, while df.groupby(\"col1\")[\"col2\"].describe() only summarises data in col1 and col2 group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e8fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3a\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "group_sex_stats = df.groupby(\"pclass\")[\"sex\"].describe()\n",
    "print (group_sex_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215c38e",
   "metadata": {},
   "source": [
    "Although gpt tells me my code is correct, it helps me add import pandas as pd. So gpt is better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5745e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3b\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\"\n",
    "df = pd.read_csv(url)\n",
    "group_sex_stats = df.groupby(\"pclass\")[\"sex\"].describe()\n",
    "print (group_sex_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e2ce71",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Gpt corrected the error at the first time, so it is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5171365",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3c\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "group_sex_stats = Df.groupby(\"pclass\")[\"sex\"].describe()\n",
    "print (group_sex_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a22a18",
   "metadata": {},
   "source": [
    "Gpt replaced Df by df, so it is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863bada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3d\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url\n",
    "group_sex_stats = df.groupby(\"pclass\")[\"sex\"].describe()\n",
    "print (group_sex_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d88b8a4",
   "metadata": {},
   "source": [
    "It added the missing closing parenthesis ) for pd.read_csv(url)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff891856",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3e\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "group_sex_stats = df.groupby(\"pclass\")[\"sex\"].describde()\n",
    "print (group_sex_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac14eea",
   "metadata": {},
   "source": [
    "Corrected the typo from .describde() to .describe()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be4d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3f\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "group_sex_stats = df.groupby(\"pclass\")[\"Sex\"].describe()\n",
    "print (group_sex_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547e9dc7",
   "metadata": {},
   "source": [
    "Changed \"Sex\" to \"sex\" in the line df.groupby(\"pclass\")[\"sex\"].describe()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb46f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3g\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "group_sex_stats = titanic_df.groupby(\"pclass\")[\"sex\"].describe()\n",
    "print (group_sex_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4500fff",
   "metadata": {},
   "source": [
    "Changed titanic_df to df because you used df when loading the dataset with pd.read_csv.\n",
    "gpt link:https://chatgpt.com/share/66e3425f-88e0-8001-837c-2110ee7390c9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ff283",
   "metadata": {},
   "source": [
    "Question9: yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
